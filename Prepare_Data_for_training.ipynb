{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prepare Data for training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFqQJbJm2I1As8F6Hrejlj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoGian/NLP-with-Disaster-Tweets/blob/master/Prepare_Data_for_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or2Oar0DZ2ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f52106dc-c19c-4e49-85a5-a1b1a0f0645e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOUuThlDhFg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import random\n",
        "import pickle \n",
        "import gc\n",
        "import os\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZZLwjxkHan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6PwMGshPai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TARGET_COLUMN = 'target'\n",
        "LOCATION_COLUMN = 'location'\n",
        "KEYWORD_COLUMN = 'keyword'\n",
        "METADADATA_COLUMNS = [LOCATION_COLUMN] + [KEYWORD_COLUMN]\n",
        "TEXT = 'text'\n",
        "\n",
        "TRAIN_DATASET_PATH = '/content/drive/My Drive/NLP with Disaster Tweets/train_cleared.csv'\n",
        "TEST_DATASET_PATH = '/content/drive/My Drive/NLP with Disaster Tweets/test_cleared.csv'\n",
        "GLOVE_PATH = \"/content/drive/My Drive/Glove/glove.840B.300d.pkl\"\n",
        "CRAWL_PATH = \"/content/drive/My Drive/Crawl/crawl-300d-2M.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7wQg3-7hpG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(TRAIN_DATASET_PATH)\n",
        "test_df =  pd.read_csv(TEST_DATASET_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhHljgy2hxqA",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG5JLMYbh0tE",
        "colab_type": "text"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebOsQdw7hsgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df , val_df = train_test_split(train_df,test_size = 0.15,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDWPTdNMi6jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train_df[TEXT].astype(str)\n",
        "y_train = train_df[TARGET_COLUMN].astype(int).values\n",
        "\n",
        "x_val = val_df[TEXT].astype(str)\n",
        "y_val = val_df[TARGET_COLUMN].astype(int).values\n",
        "\n",
        "x_test = test_df[TEXT].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7S-QQRpjTxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create tokenizer for our data\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=False)\n",
        "tokenizer.fit_on_texts(list(x_train) + list(x_test) + list(x_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C92qearokBzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert text data to numerical indexes\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_val = tokenizer.texts_to_sequences(x_val)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "\n",
        "#pad data up to MAX_LEN (note that we truncate if there are more than MAX_LEN tokens)\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val, maxlen=MAX_LEN)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EotqfczhkXtm",
        "colab_type": "text"
      },
      "source": [
        "## Build matrix with embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbDaKgBWkVgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embeddings(path):\n",
        "    with open(path,'rb') as f:\n",
        "        embedding_index = pickle.load(f)\n",
        "    return embedding_index\n",
        "\n",
        "def build_matrix(word_index, path):\n",
        "    embedding_index = load_embeddings(path)\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "    unknown_words = []\n",
        "    \n",
        "    for word, i in word_index.items():\n",
        "        try:\n",
        "            embedding_matrix[i] = embedding_index[word]\n",
        "        except KeyError:\n",
        "            unknown_words.append(word)\n",
        "    return embedding_matrix, unknown_words "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTmC_ZlGkfLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "60e375df-6686-480d-aec1-b22af294372e"
      },
      "source": [
        "glove_embedding_matrix,unknown_words = build_matrix(tokenizer.word_index,GLOVE_PATH)\n",
        "print('n unknown words (glove): ', len(unknown_words))\n",
        "print('n known words (glove): ', len(glove_embedding_matrix))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n unknown words (glove):  5634\n",
            "n known words (glove):  27282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia0VYHMikhBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8961fc15-6421-4e81-8f36-74997fde0693"
      },
      "source": [
        "crawl_embedding_matrix,unknown_words = build_matrix(tokenizer.word_index,CRAWL_PATH)\n",
        "print('n unknown words (crawl): ', len(unknown_words))\n",
        "print('n known words (crawl): ', len(crawl_embedding_matrix))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n unknown words (crawl):  5689\n",
            "n known words (crawl):  27282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHbI_70dki6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97529922-ea93-45d5-8706-4148253f57a3"
      },
      "source": [
        "embedding_matrix = np.concatenate([glove_embedding_matrix, crawl_embedding_matrix], axis=-1)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27282, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpwKA-TUkk-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(os.path.join('/content/drive/My Drive/NLP with Disaster Tweets/', 'embedding_matrix'),embedding_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osSJUQAYk3PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "af855c7c-1789-495b-b458-10201819288d"
      },
      "source": [
        "del crawl_embedding_matrix\n",
        "del glove_embedding_matrix\n",
        "gc.collect()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kp6edr0lJlA",
        "colab_type": "text"
      },
      "source": [
        "## Save sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cum2_3Hbk4rS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "69d857c3-1b9a-4799-f452-c5aa812a67d3"
      },
      "source": [
        "train_set = pd.DataFrame(y_train,columns=[TARGET_COLUMN])\n",
        "seq = pd.DataFrame(x_train)\n",
        "train_set = pd.concat([train_set,seq],axis=1)\n",
        "len(train_set)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rvhvlvDlcxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "540c560a-5162-4ccc-f5bf-4ef6fa020de4"
      },
      "source": [
        "val_set = pd.DataFrame(y_val,columns=[TARGET_COLUMN])  \n",
        "seq = pd.DataFrame(x_val)\n",
        "val_set = pd.concat([val_set,seq],axis=1)\n",
        "len(val_set)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Lid9Oultga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1ecf9b1-34da-4838-a4db-77bc8cbfd629"
      },
      "source": [
        "test_set = pd.DataFrame(x_test)\n",
        "len(test_set)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLaaOrKVl31j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set.to_pickle(\"/content/drive/My Drive/NLP with Disaster Tweets/train_set.pkl\")\n",
        "test_set.to_pickle(\"/content/drive/My Drive/NLP with Disaster Tweets/test_set.pkl\")\n",
        "val_set.to_pickle(\"/content/drive/My Drive/NLP with Disaster Tweets/val_set.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}